<h1>Building trust in ML Systems</h1>

<p>
    As builders of AI and ML systems, much time and effort is spent in building our own trust with the technology we are developing. This can take the form of model accuracy metrics, compute efficiency, and core functionality achieved. There is another, often more daunting, step to be considered: building trust in the technology with non-technical users and other stakeholders who will be impacted by its adoption.
</p>

<p>
    In this talk, we explore four pillars of building trust in AI systems with non-technical stakeholders:
    <ol>
        <li>Describing performance relative to an interpretable and intuitive baseline.</li>
        <li>Quantifying uncertainty as part of the delivery process.</li>
        <li>Sharing the why in non-binary decision processes.</li>
        <li>Designing for 2nd order process effects.</li>
    </ol>
</p>

<p>
    After this talk, machine learning practitioners and managers will be equipped to build trust in the products they develop - enabling maximum value and impact from their work.
</p>

<h2>Why "trust"</h2>

<p>
    Key question: Why is trust an essential requirement for meaningful adoption?
    Answer: There's not the time, resources, or talent resevoirs to do everything yourself.
</p>

<p>
    Think back on your day so far: What systems and what people have you trusted?
</p>

<ul>
    <li>A shop to prepare your coffee?</li>
    <li>A packaged food company to make and preserve your breakfast?</li>
    <li>A pilot or driver to get you here today?</li>
    <li>An elevator to safely bring you up or down a building?</li>
    <li>An architect to design a safe building or house for you to stay in?</li>
</ul>

<p>
    Without the ability to trust other people and systems you would be at a significant (and probably fatal) disadvantage in life - unable to take advantage of the time, effort, and expertise of others as well as the relevant economies of scale.
</p>

<h2>Why distrust?</h2>

<p>
    If trust is a vital trait for human survival, then so is distrust. This is probably obvious to anyone who has ever checked their email or purchased fresh rasberries. In a world where we must trust systems and individuals, there is still substantial value in skepticism. What reason do we have for distrust? Let's name a few:
</p>

<h3>Bad actors</h3>

There are of course scammers and other people deliberately trying to trick us out of our time, money, or personal information. These are swindlers who are clearly violating laws and/or social conventions. These certainly exist in the world, but if we are providing a data product we will not have to spend too much time convincing our would-be users that we do not fall into this bucket.

<h3>Puffery</h3>

<p>
    Have you ever seen a sign in a diner declaring they have the world's best coffee? Most of us would not take this declaration seriously (unless you are "Buddy" from Elf).
</p>

<img src="elf.jpg" alt="A picture of me smiling." style="width:40%">

<p>
    Instead we are naturally skeptical of those who are trying to convince us of the value of products they are trying to buy - and it pays to be so. If we bought into every idea or product ever pitched to us, we would find ourselves intellectually and financially destitute.
</p>

<p>
    Indeed, in my experience this is the most common initial distrust we encounter as practitioners of machine learning. We come in weilding all sorts of magical sounding evidence about AUC, PPV, R-squared, confusion matrices, and the like promising to improve efficiency, reduce costs, grow engagement, and eliminate dental carries if our potential users would only adopt our process.
</p>

<p>
    Now while this may be a common mechanism of distrust, it is reasonably straightforward to address. Mainly it involves being transparent, straightforward, and helping your customer understand your product. 
</p>

<p>
    Maybe you grab someone's attention by declaring that you have the world's best coffee. It's better to explain how you source and roast your beans. It's even better to just let them try a cup.
</p>

<h3>Mistakes of others</h3>

<p>
    When I was a kid, grown ups were always double-checking their reciepts at the grocery store. (This seems less common now - maybe it's considered rude or maybe today's grown ups don't have the time or attention span to care). I don't think the suspicion was ever really that the grocery store checker would deliberately double charge for an item or fail to honor a coupon (surely they do not benefit from doing so), but rather that a mistake might have been made - a mistake that would ultimately cost them money.
</p>

<p>
    In the AI space, I think we see all three of these reasons to distrust.
</p>



<h2>How trust works</h2>

What are the core concepts that drive our decision to trust or not trust something or someone.

<h3>Example</h3>

<h2>Baselines - Trust as an transitive concept</h2>

If I trust A, and A trusts B, then I trust B.

<h3>Example</h3>

<h2>Quantifying uncertainty - demonstrating honesty</h2>

We trust people that are honest. Being wrong isn't the issue, it's being confident and wrong that is the issue. Quantifying the uncertainty behind statements is essential to building trust, but it is usually a technically difficult afterthought for most machine learning systems.

<h3>Example</h3>

<h2>Showing your work - the reasons are as important as the answer</h2>

When you share your thought process, we can empathize with your conclusion and perhaps be persuaded by it. Moreover, the reasoning may itself be valuable - see the concept of a <a href="https://en.wikipedia.org/wiki/Porism">porism</a>.

<h3>Example</h3>

<h2>Higher order effects - we trust those who understand us</h2>

This is a murky idea - but basically the situation we're trying to avoid here is someone saying "you don't get it." This can happen in many ways, but a common one is when we fail to grasp the full scope of the process we are trying to replace.

<h3>Example</h3>

